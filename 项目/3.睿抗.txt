项目负责的什么？
#最开始有官方给的代码框架，也有往届的代码，但是因为任务每年都会变，需要我们自己修改代码的细节

困难？
#速度匹配问题
	采集完第一版车道模型数据的时候，我们训了模型，但是车永远会在第一个弯道飞出去，当时以为是模型问题，又采样了好几版，还是解决不了，最后发现是因为采样速度和实际测试的速度不一样
采样内容：图片+对应的json文件

#端口匹配问题
	后期发现车偶尔一开始就乱跑，排除巡航模型问题后，在出门时候直接保存摄像头图片，发现摄像头编号有误，三个摄像头在一个扩展坞上连接了主板，感觉是因为板子老化上电顺序的问题，或是接口松动，导致dev下video的名称一直在变，验证发现确实是这样的。因此采用udev规则，对指定串口设置对应的dev名称，再修改camera类里面对摄像头的调用规则，解决了这个问题

#光线问题模型识别
	因为我们备赛的场地在教学楼一楼，有一个大落地窗，经常有阳光照进来，所以我们考虑到了这个问题，虽然官方的训练baseline有对输入图像进行随机数据增强的措施比如随机调整对比度、色调、亮度，但地上的光斑有时候导致图像整体色调不均匀，我们就通过多采样本来避免，老师也提到之前比赛有人打着太阳伞跟着车跑

为什么选择PaddlePaddle框架？它有哪些优势，例如与TensorFlow或PyTorch相比？
#官方要求的，我了解到因为是国产，对国内开发者很友好，并且是免费开源的

CNN模型的具体架构是什么？（例如VGG、ResNet、MobileNet）是直接采用现成模型还是自己设计的？
#五层卷积、随机池化、两层全连接，线性层输出一个角度预测值

训练数据的采集和标注是如何完成的？是否遇到过数据量不足的问题？如何解决？
#车道不需要，侧面手动用labelme打标签，最后是图片+json数据

在训练过程中，是否遇到过模型过拟合的问题？采取了哪些防范措施？

SSD算法优点？
#不同特征图对应不同的目标，适配不同形状和大小的目标

比赛任务包括“识别目标、取物、击打目标”等多种操作，如何分解这些任务的？不同任务之间的逻辑是如何实现的？

定位误差主要来源于哪些方面？例如，传感器误差、算法误差还是环境因素（如遮挡）？

机器人整体系统架构是怎样的？如何设计不同模块（如感知、决策、控制）的协作机制的？
#上位机：EdgeBoard  
通过ssh连接

下位机：鲸鱼机器人MC601控制器
6路PWM输出接口，2路模拟输入接口，1路UART硬件接口
连俩电机驱动板

数据从摄像头采集到模型推理输出，再到机械臂操作，这个过程的延迟如何控制？

比赛中的环境是固定场景还是随机生成的？环境变化对目标检测和机器人定位有哪些挑战？

是否模拟了比赛中的复杂场景进行测试？例如障碍物遮挡、光线干扰等

比赛中是否遇到过机器人失灵或识别失败的情况？如果有，是如何快速定位和解决问题的？
#连着车跑看输出

如果未来要将机器人升级为多任务系统（如同时完成多目标识别和路径规划），系统需要做哪些改进？


